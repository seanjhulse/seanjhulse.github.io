<!DOCTYPE html>
<html lang="en-US">

	<head>
		<title>Machine Learning: Classifiers</title>
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<link href="../stylesheets/app.css" rel="stylesheet" />
		<script src="../scripts/index.js" type="text/javascript"></script>

		<link href="https://cdn.jsdelivr.net/gh/kognise/water.css@latest/water.min.css" rel="stylesheet">
	</head>

	<body>
    <a href="/">Home</a>
    <a href="/#/posts">Posts</a>
		<main>
			<section>
        <h1>Adults Only</h1>
        <p>Nah, I'm just playing. We're doing some machine learning (ML) on a database: <a href="https://archive.ics.uci.edu/ml/datasets/Adult">https://archive.ics.uci.edu/ml/datasets/Adult</a>. It has been a while since I've done any ML. And I've never really used SciKit, a Python library dedicated to ML. So, I kind of did what I always do: hop in code first, understand nothing, learn something, use it wrong, then relearn it, use it right, clobber something together.</p>
      </section>
      <section>
        <h2>Code</h2>
<pre>
from sklearn import tree
from sklearn import preprocessing
import csv
import numpy as np

# initialize some values
clf = tree.DecisionTreeClassifier()
le = preprocessing.LabelEncoder()
data = np.genfromtxt("adult.data", delimiter=",",dtype=None, encoding="utf8")

# create numeric labels for our string categories
categories = []
for row in data:
  row = list(row)
  if row[1] not in categories: categories.append(row[1])
  if row[3] not in categories: categories.append(row[3])
  if row[5] not in categories: categories.append(row[5])
  if row[6] not in categories: categories.append(row[6])
  if row[7] not in categories: categories.append(row[7])
  if row[8] not in categories: categories.append(row[8])
  if row[9] not in categories: categories.append(row[9])
  if row[13] not in categories: categories.append(row[13])
le.fit(categories)

'''
Just some bad coding standards because I did this on a Friday night with a beer
in one hand and Family Guy in the background

Transform a row into a numerical vector thanks to the categorical pre-processing
of the data. We could do this statically and save a new CSV file with the data
having been processed, but what am I? A saint?

@params row a plain text version of the data in a tuple
@return {list} of each value transformed

'''
def transform_data(row):
  val0 = row[0]
  val1 = le.transform([row[1]])[0]
  val2 = row[2]
  val3 = le.transform([row[3]])[0]
  val4 = row[4]
  val5 = le.transform([row[5]])[0]
  val6 = le.transform([row[6]])[0]
  val7 = le.transform([row[7]])[0]
  val8 = le.transform([row[8]])[0]
  val9 = le.transform([row[9]])[0]
  val10 = row[10]
  val11 = row[11]
  val12 = row[12]
  val13 = le.transform([row[13]])[0]
  return [val0, val1, val2, val3, val4, val5, val6, val7, val8, val9, val10, val11, val12, val13]

'''
Generic function to test a row in our existing dataset to confirm our model
@param row_index
'''
def test_input(row_index):
  row = data[row_index]
  row = list(row)
  print(row)
  val = transform_data(row)
  prediction = clf.predict(np.matrix(val))
  log_prediction(prediction)

'''
Generic function to test a custom row of new data to test our model
@param vals list of values
'''
def custom_input(vals):
  print(vals)
  val = transform_data(vals)
  prediction = clf.predict(np.matrix(val))
  log_prediction(prediction)

'''
Logs the meaning of each value
@param prediction 0 / 1
'''
def log_prediction(prediction):
  if prediction:
    print("Under 50")
  else:
    print("Over 50")

X = []
Y = []
for row in data:
  row = list(row)
  val = transform_data(row)
  val14 = row[14]
  if(val14 == " <=50K"):
    val14 = 1
  else:
    val14 = 0

  X.append(val)
  Y.append([val14])

X = np.matrix(X)
Y = np.matrix(Y)

clf = clf.fit(X, Y)

# testing our model
test_input(8)
test_input(52)
test_input(157)
custom_input([25, ' Private', 10000, ' Bachelors', 14, ' Unmarried', ' Sales', ' Husband', ' White', ' Male', 55000, 0, 0, ' United-States'])
custom_input([71, ' Self-emp-not-inc', 494223, ' Some-college', 10, ' Separated', ' Sales', ' Unmarried', ' Black', ' Male', 0, 1816, 2, ' United-States'])
</pre>
      <h2>How it works?</h2>
      <p>Well, if I knew that, I wouldn't be talking to you schmucks, would I? For real, though, it's not too complex. Our data set looks like this:</p>
<pre>
    39, State-gov, 77516, Bachelors, 13, Never-married, Adm-clerical, Not-in-family, White, Male, 2174, 0, 40, United-States, <=50K
</pre>
      <p>It's a series of random information about an individual person. There are thousands of these rows. The values are not super important or they are self-explanatory. You can check out the dataset using the link above. The important knowledge is: columns 0 -> 13 are <strong>X</strong> parameters and column 14 is the <strong>Y</strong> values. Our goal is to somehow make this almagamation of <strong>X</strong> values <i>mean something</i> in relation to each row's <strong>Y</strong>.</p>
      </section>
      <section>
        <h2>Classification Models</h2>
        <p>DecisionTreeClassifier is a class capable of performing multi-class classification on a dataset. As with other classifiers, DecisionTreeClassifier takes as input two arrays: an array X, sparse or dense, of size [n_samples, n_features] holding the training samples, and an array Y of integer values, size [n_samples], holding the class labels for the training samples.</p>
        <p>In the case of our data, we're a little screwed. We can't (for some reason) use String values in our model! You'd hope that these kinds of prediction models wouldn't require manual classification of string data and would - instead - be able to assume an enum for each unique, new, value, but maybe that's too expensive. So, first, we develop our own categories. I did it the most efficient way possible /s.</p>
        <p>Well, anyways, that's what this does. It iterates over all the data, finds unique values by performing an O(n) scan of the the categories list (ugh) and then it fits the values to those unique categories. The <strong>LabelEncoder()</strong> essentially maps a unique vector to each string value. Avoiding duplicates was just in case it doesn't account for that. I'm not sure if it does. But we <i>don't</i> want to label encode all values because each other numerical value is unique and likely to never be repeated again. So we have to pick out the columns we know are strings.</p>
<pre>
clf = tree.DecisionTreeClassifier()
le = preprocessing.LabelEncoder()
data = np.genfromtxt("adult.data", delimiter=",",dtype=None, encoding="utf8")

# create numeric labels for our string categories
categories = []
for row in data:
  row = list(row)
  if row[1] not in categories: categories.append(row[1])
  if row[3] not in categories: categories.append(row[3])
  if row[5] not in categories: categories.append(row[5])
  if row[6] not in categories: categories.append(row[6])
  if row[7] not in categories: categories.append(row[7])
  if row[8] not in categories: categories.append(row[8])
  if row[9] not in categories: categories.append(row[9])
  if row[13] not in categories: categories.append(row[13])
le.fit(categories)
    
</pre>
      <p>At the very end, we fit the categories to our <strong>LabelEncoder</strong> model.</p>
      <p>So, now our data is entirely classifiable. It's able to be interpreted as a series of meaningful numbers that represent our data. So, the next step is to transform the data using our <strong>LabelEncoder</strong> model and convert it for a SciKit numpy matrix.</p>
      </section>
      <section>
        <h2>Fit the data to the Model</h2>
        <p>We just iterate over the data and create numpy matrices to fit the model's expected shape for classification. If you know matrices, you know we want the shapes to be comparable. So, we need to create viable numpy matrices of the data. First, iterate over the data, transform the data, then create matrices from it. Alternatively, we could be mature adults (am I going to be flagged by Google) and program like pros. Pros would create numpy matrices from the start that match the expected shape of the data we're inserting, but what am I? A scientist? Instead, just create a list, fill the list, and convert it.</p>
<pre>
X = []
Y = []
for row in data:
  row = list(row)
  val = transform_data(row)
  val14 = row[14]
  if(val14 == " <=50K"):
    val14 = 1
  else:
    val14 = 0

  X.append(val)
  Y.append([val14])

X = np.matrix(X)
Y = np.matrix(Y)
</pre>
      <p>See how easy that is? The only new custom code is we take the last value in each row and assume any known <strong>Y</strong> value that isn't under 50 is assumed over 50 and we reassign it to 1 or 0 respectively.</p>
      <p>Great so, whaddya-gonna-do-about-it? Yeah, I thought so. We'd fit our data and test our model.</p>
<pre>
clf = clf.fit(X, Y)

# testing our model
test_input(8)
test_input(52)
test_input(157)
custom_input([25, ' Private', 10000, ' Bachelors', 14, ' Unmarried', ' Sales', ' Husband', ' White', ' Male', 55000, 0, 0, ' United-States'])
</pre>
      <p>Our output confirms our model at least responds correctly for known values. It's hard to tell if our custom output returns our "expected" value. If you're curious, we get "Over 50" for a person who works in a private industry, making 55K a year, is white, unmarried, a husband(?), and works in sales. Seems like an interesting guy. Seems also like he fluctuates in between a lot of expectations. But maybe that's the point. What we might expect is not exactly what we get.</p>
      </section>
      <section>
        <h2>How do you do your own classifiers?</h2>
        <p>Just read and play with data. My data came from UCI. It started on an adventure to classify IR spectroscopy on chemicals, but I couldn't find large enough datasets. So, UCI it is. They are a great resource for testing your abilities. I highly recommend <strong>not</strong> building your own classifiers if you just want to learn how to use ML. ML is a tough field. It requires a lot of math, patience, and attention. But <a href="https://scikit-learn.org/stable/index.html">SciKit</a> comes from the gods. Pythonic, easy to use, deals with idiots like me? It's a match made in heaven. You should follow some of their tutorials and see how far you can go!</p>
      </section>
    </main>
	</body>
</html>